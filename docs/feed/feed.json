{
	"version": "https://jsonfeed.org/version/1.1",
	"title": "stinky.blog",
	"language": "en",
	"home_page_url": "https://stinky.blog/",
	"feed_url": "https://stinky.blog/feed/feed.json",
	"description": "brain of brian. notes about fun things i&#39;m learning",
	"author": {
		"name": "Brian",
		"url": "https://stinky.blog/about-me/"
	},
	"items": [
		{
			"id": "https://stinky.blog/blog/zfs-fileserver/",
			"url": "https://stinky.blog/blog/zfs-fileserver/",
			"title": "ZFS Fileserver: LXC+Dataset vs VM+Zvol",
			"content_html": "<h2 id=\"intro-recap\" tabindex=\"-1\">Intro / recap <a class=\"header-anchor\" href=\"https://stinky.blog/blog/zfs-fileserver/\">#</a></h2>\n<p>Lately, I have been doing some benchmarking of my ZFS pools.  I have been trying to learn the performance impact of different volblocksizes when running VMs on ZFS.</p>\n<p>Selecting the wrong volblocksize can cause serious performance issues.  Even though my VMs been trucking along just fine, I wanted to learn more about this and how to properly optimize it for production workloads.</p>\n<p>You can see the results of <a href=\"https://stinky.blog/blog/zfs-bench/\">round 1</a> and <a href=\"https://stinky.blog/blog/zfs-bench2/zfs-volblocksize-round-2/\">round 2</a> here.</p>\n<h2 id=\"vm-vs-lxc\" tabindex=\"-1\">VM vs LXC <a class=\"header-anchor\" href=\"https://stinky.blog/blog/zfs-fileserver/\">#</a></h2>\n<p><strong>LXC:</strong>\nOriginally, I ran my fileserver in a lightweight LXC container, using a storage-backed mount in Proxmox.  I passed the mount directory (ext4) into the VM and shared it via samba/nfs.  Performance was great and it worked like a charm.  The only major downside for me was that Proxmox Backup Server would then have to scan the entire disk in order to make the daily backups.  LXC containers don't have a way to track changes to files, so even incremental backups still take way too long.  I was using 5TB spinning disks at the time, and backups were taking about 3.5 hours at a minimum, even if there was nothing new to backup.</p>\n<p><strong>VM:</strong>\nUnlike LXCs, VMs do have a way to track which files have changed: dirty pages.  As long as the VM is online and has not rebooted since the last backup, it will only scan and transfer new or modified files.  This cut my backup times down from 3 hours to 3 minutes.</p>\n<p>I have run my fileserver in a VM on a ZFS pool for about a year and a half now.  It has worked great.  I love the integration with Proxmox Backup Server, which allows me to very quickly backup, restore, and migrate the entire VM along with all of its data.</p>\n<p>VMs running on ZFS pools in Proxmox introduce the volblocksize concept though, instead of using a recordsize.  While a sub-optimal recordsize isn't that big of a deal, setting the wrong volblocksize can be much worse.  That has been what I wanted to learn about through my testing.</p>\n<h2 id=\"test-results-so-far\" tabindex=\"-1\">Test results so far <a class=\"header-anchor\" href=\"https://stinky.blog/blog/zfs-fileserver/\">#</a></h2>\n<p>The benchmarks I've run so far have led to more questions than answers.  The results are confusing.  I'm not sure if my testing methodology is even sound for what I'm looking to learn.  There is very little information online about volblocksize optimization and how to test it.  I think the general idea is that you should avoid zvols like the plague unless you know exactly what size blocks will be written from your workload, and you are able to tailor each zvol to the specific data that it will contain.  From my testing, speeds increase dramatically when pushing the volblocksize from the default 8k to as high as 64k.  I don't have a heavy database or write/rewrite in place workload to really test the downside of that change, though.</p>\n<p>So with that in mind, let's see if there's a way to avoid volblocksize completely, while retaining my favorite benefits of the VM.</p>\n<h2 id=\"back-to-lxc\" tabindex=\"-1\">Back to LXC <a class=\"header-anchor\" href=\"https://stinky.blog/blog/zfs-fileserver/\">#</a></h2>\n<p>So, I will complete the circle and go back to using a LXC.  In order to avoid the super long backup times, I will switch up my backup process.</p>\n<p>Proxmox Backup Server uses its own method to create incremental backups, which requires either scanning the entire disk or using dirty-pages for a VM.  I will use zfs snapshots instead.  Since my Proxmox Backup Server has a 48TB ZFS pool, I can just use zfs send/receive to back them up on the same pool but without the long scan and transfer times.  Sending an incremental snapshot with zfs send should be nearly instant, no matter what the state of the container is.</p>\n<p>Unfortunately, it's not possible to do ZFS snapshots inside the PBS gui yet.  That's ok, though, since the commands should be pretty easy and scriptable.  I will just have PBS continue to backup the container itself with the backup job in the gui.</p>\n<p>There is one extra hoop to jump through in order to mount the zfs dataset inside the LXC, as well.  The datasets need to be created and then added to the container manually, rather than creating a fixed-size dataset within the Proxmox gui.</p>\n<h2 id=\"setup\" tabindex=\"-1\">Setup <a class=\"header-anchor\" href=\"https://stinky.blog/blog/zfs-fileserver/\">#</a></h2>\n<p>First, I created a new dataset (fileserver) on my zpool (fast):</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">zfs create fast/fileserver</code></pre>\n<p>Then I configured permissions on the proxmox host.  <a href=\"https://blog.kye.dev/proxmox-zfs-mounts\">This is a great guide</a> on how to configure permissions for this specific scenario.  TLDR: Proxmox masks the true uid/gid inside containers for security reasons.  In order to share files on the host from inside an unprivileged container, this workaround (or manual user-mapping) is necessary.</p>\n<p>The uid/gid obfuscation works by adding 100,000 to whatever the container's value is.  So uid 1000 in the container is uid 101000 on the host.</p>\n<p>So I will make a fileserver users group with gid 110000 on the Proxmox host:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">groupadd</span> <span class=\"token parameter variable\">-g</span> <span class=\"token number\">110000</span> file_users</code></pre>\n<p>And then a user:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">useradd</span> files <span class=\"token parameter variable\">-u</span> <span class=\"token number\">101000</span> <span class=\"token parameter variable\">-g</span> <span class=\"token number\">110000</span> <span class=\"token parameter variable\">-m</span> <span class=\"token parameter variable\">-s</span> /bin/bash</code></pre>\n<p>chown the dataset to the new user and group:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">chown</span> <span class=\"token parameter variable\">-R</span> files:file_users /fast/fileserver/</code></pre>\n<p>Then I created a new unprivileged debian 12 container.</p>\n<p>Now start the container and add the user and group inside there:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">groupadd</span> <span class=\"token parameter variable\">-g</span> <span class=\"token number\">10000</span> file_users\n<span class=\"token function\">useradd</span> files <span class=\"token parameter variable\">-u</span> <span class=\"token number\">1000</span> <span class=\"token parameter variable\">-g</span> <span class=\"token number\">10000</span> <span class=\"token parameter variable\">-m</span> <span class=\"token parameter variable\">-s</span> /bin/bash</code></pre>\n<p>Shutdown the container.</p>\n<p>Finally, we just have to add the mountpoint to the container configuration file.  You can do this manually or just use pct set on the proxmox host:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">pct <span class=\"token builtin class-name\">set</span> <span class=\"token number\">109</span> <span class=\"token parameter variable\">-mp0</span> /fast/fileserver,mp<span class=\"token operator\">=</span>/mnt/files</code></pre>\n<p>Now run the container again.</p>\n<p>Tadaaaaaa:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">root@zfs-test:/mnt<span class=\"token comment\"># ls</span>\nfiles\nroot@zfs-test:/mnt<span class=\"token comment\"># </span></code></pre>\n<p>Now before I get too excited and set up NFS and Samba, I'd like to just run the same benchmark I ran in <a href=\"https://stinky.blog/blog/zfs-bench/\">round 1</a>.  Let's see how a raw dataset with 128k recordsize compares to all those volblocksizes.</p>\n<h2 id=\"quick-bench\" tabindex=\"-1\">Quick bench <a class=\"header-anchor\" href=\"https://stinky.blog/blog/zfs-fileserver/\">#</a></h2>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">fio <span class=\"token parameter variable\">--name</span><span class=\"token operator\">=</span>random-write <span class=\"token parameter variable\">--rw</span><span class=\"token operator\">=</span>randrw <span class=\"token parameter variable\">--bs</span><span class=\"token operator\">=</span>4k <span class=\"token parameter variable\">--size</span><span class=\"token operator\">=</span>4g <span class=\"token parameter variable\">--numjobs</span><span class=\"token operator\">=</span><span class=\"token number\">1</span> <span class=\"token parameter variable\">--iodepth</span><span class=\"token operator\">=</span><span class=\"token number\">1</span> <span class=\"token parameter variable\">--runtime</span><span class=\"token operator\">=</span><span class=\"token number\">60</span> <span class=\"token parameter variable\">--time_based</span> <span class=\"token parameter variable\">--end_fsync</span><span class=\"token operator\">=</span><span class=\"token number\">1</span></code></pre>\n<p>4k random read/write:\n<picture><source type=\"image/avif\" srcset=\"https://stinky.blog/img/Hqas4cqhHk-666.avif 666w\"><source type=\"image/webp\" srcset=\"https://stinky.blog/img/Hqas4cqhHk-666.webp 666w\"><img alt=\"4k random read/write performance\" loading=\"lazy\" decoding=\"async\" src=\"https://stinky.blog/img/Hqas4cqhHk-666.png\" width=\"666\" height=\"500\"></picture></p>\n<p>The VM is a bit faster than the container for tiny writes.  What about 1M random?</p>\n<p>1M random read/write:\n<picture><source type=\"image/avif\" srcset=\"https://stinky.blog/img/aTLJCUWlVl-666.avif 666w\"><source type=\"image/webp\" srcset=\"https://stinky.blog/img/aTLJCUWlVl-666.webp 666w\"><img alt=\"1M random read/write performance\" loading=\"lazy\" decoding=\"async\" src=\"https://stinky.blog/img/aTLJCUWlVl-666.png\" width=\"666\" height=\"500\"></picture></p>\n<p>The container is <strong>102% faster</strong> than the VM here.  It transferred <strong>72GB</strong> while the VM only transferred <strong>36GB.</strong>  Pretty cool!</p>\n<h2 id=\"samba-time\" tabindex=\"-1\">samba time. <a class=\"header-anchor\" href=\"https://stinky.blog/blog/zfs-fileserver/\">#</a></h2>\n<p>Just installed the base ubuntu &quot;samba&quot; package.  Made a basic smb.conf</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token punctuation\">[</span>files<span class=\"token punctuation\">]</span>\n   path <span class=\"token operator\">=</span> /mnt/files\n   valid <span class=\"token function\">users</span> <span class=\"token operator\">=</span> files\n   guest ok <span class=\"token operator\">=</span> no\n   writable <span class=\"token operator\">=</span> <span class=\"token function\">yes</span>\n   browseable <span class=\"token operator\">=</span> <span class=\"token function\">yes</span></code></pre>\n<p>created user:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">smbpasswd <span class=\"token parameter variable\">-a</span> files</code></pre>\n<h2 id=\"results\" tabindex=\"-1\">Results <a class=\"header-anchor\" href=\"https://stinky.blog/blog/zfs-fileserver/\">#</a></h2>\n<p>Ran crystaldiskmark on the network share again, from my windows11 PC connected via 10GbE.</p>\n<p>In the container:</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://stinky.blog/img/tpiLKNgtFo-482.avif 482w\"><source type=\"image/webp\" srcset=\"https://stinky.blog/img/tpiLKNgtFo-482.webp 482w\"><img alt=\"crystaldiskmark results in container with zfs dataset mount, network share\" loading=\"lazy\" decoding=\"async\" src=\"https://stinky.blog/img/tpiLKNgtFo-482.png\" width=\"482\" height=\"355\"></picture></p>\n<p>In the VM:</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://stinky.blog/img/qzUq7bzt-Z-482.avif 482w\"><source type=\"image/webp\" srcset=\"https://stinky.blog/img/qzUq7bzt-Z-482.webp 482w\"><img alt=\"64k volblocksize vm crystaldiskmark results\" loading=\"lazy\" decoding=\"async\" src=\"https://stinky.blog/img/qzUq7bzt-Z-482.png\" width=\"482\" height=\"352\"></picture></p>\n<p><strong>It's a lot faster!!</strong></p>\n<p>Nearly doubled the write performance when writing to the dataset directly rather than through a zvol.</p>\n<p>Looking forward to learning how to automate snapshots and zfs send them to the Proxmox Backup Server!  Will post a follow up.</p>\n<p>Happy homelabbing!</p>\n",
			"date_published": "2024-03-23T00:00:00Z"
		}
		,
		{
			"id": "https://stinky.blog/blog/thinkpad-backup/thinkpad-backup-script/",
			"url": "https://stinky.blog/blog/thinkpad-backup/thinkpad-backup-script/",
			"title": "Thinkpad Backup Script",
			"content_html": "<h2 id=\"fast-backups\" tabindex=\"-1\">Fast backups <a class=\"header-anchor\" href=\"https://stinky.blog/blog/thinkpad-backup/thinkpad-backup-script/\">#</a></h2>\n<p>I have been doing super lazy backups of my thinkpad for a while.  I just rsync the whole home folder to my fileserver.  That has been working okay, except that now I have a ton of files I'd like to exclude from the backup to speed it up a bit.  I'd also like the backup to run periodically in the background.</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token shebang important\">#!/bin/bash</span>\n<span class=\"token builtin class-name\">echo</span> <span class=\"token string\">\"Hi friend!  It's backup time.\"</span>\n\n<span class=\"token function\">sleep</span> <span class=\"token number\">1</span>\n\n<span class=\"token builtin class-name\">echo</span> <span class=\"token string\">\"Checking exclude file at <span class=\"token environment constant\">$HOME</span>/scripts/backup-excludes...\"</span>\n\n<span class=\"token function\">sleep</span> <span class=\"token number\">1</span>\n\n<span class=\"token builtin class-name\">echo</span> <span class=\"token string\">\"...\"</span>\n\n<span class=\"token function\">sleep</span> <span class=\"token number\">1</span>\n\n<span class=\"token builtin class-name\">echo</span> <span class=\"token string\">\"Backing up /home/brian to file server...\"</span>\n\n<span class=\"token comment\">#copy home folder to file server, minus exclude file:</span>\n<span class=\"token function\">rsync</span> <span class=\"token parameter variable\">-aHvzPui</span> <span class=\"token parameter variable\">--delete</span> --exclude-from<span class=\"token operator\">=</span><span class=\"token string\">'/home/brian/scripts/backup-excludes.txt'</span> <span class=\"token parameter variable\">--stats</span> <span class=\"token parameter variable\">--progress</span> /home/brian/ files:/Vault/brian/current\n\n<span class=\"token builtin class-name\">echo</span> <span class=\"token string\">\"Done!\"</span></code></pre>\n<p>Obviously the script is not actually checking anything during the echo messages but that will help to remind me where the exclude file is whenever I run the script manually.</p>\n<p>The excludes file is just a txt file that lists Downloads/ and .*</p>\n<p>The rsync flags are for archive mode, preserve hard links, verbose mode, compression enabled, Partial progress (resuming), update only if modified date changed, and itemize summary of changes.</p>\n<p>I am also using the --delete option, which will <strong>delete all files from the destination that are no longer found in the source.</strong> I snapshot the fileserver daily with Proxmox Backup Server, so I can recover any deleted files from a previous flieserver backup if I accidentally lose something.  This will just be a nice working copy of the laptop.</p>\n<p>Since I wrote a ssh config file and I use a key pair to login, I can skip password authentication and use the shortcut address files:/location.</p>\n<p>My scripts directory is added to my $PATH so I can execute the script manually by just typing</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">backup-thinkpad.sh</code></pre>\n<p>It works pretty great!</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://stinky.blog/img/aL38ajhhP5-800.avif 800w\"><source type=\"image/webp\" srcset=\"https://stinky.blog/img/aL38ajhhP5-800.webp 800w\"><img alt=\"running the thinkpad backup script\" loading=\"lazy\" decoding=\"async\" src=\"https://stinky.blog/img/aL38ajhhP5-800.png\" width=\"800\" height=\"600\"></picture></p>\n",
			"date_published": "2024-03-22T00:00:00Z"
		}
		,
		{
			"id": "https://stinky.blog/blog/zfs-bench2/zfs-volblocksize-round-2/",
			"url": "https://stinky.blog/blog/zfs-bench2/zfs-volblocksize-round-2/",
			"title": "ZFS Volblocksize Round 2",
			"content_html": "<h2 id=\"round-2\" tabindex=\"-1\">Round 2! <a class=\"header-anchor\" href=\"https://stinky.blog/blog/zfs-bench2/zfs-volblocksize-round-2/\">#</a></h2>\n<p>I did a little bit more testing on volblocksizes.  This time I discovered a faster way to switch between each size.  I just added a new disk to my existing fileserver VM after changing the pool-wide volblocksize in the Proxmox GUI.  Run the test, delete the disk, change the size again, repeat.</p>\n<p>The fileserver VM is stored on a stripe of 2x 4TB ssd.</p>\n<p>I simulated some different fileserver workloads by copying various types of files from my Windows 11 desktop to the share.  The desktop is connected via 10GbE and has a fast nvme.</p>\n<p>Here are the transfer times for each run:</p>\n<table>\n<thead>\n<tr>\n<th>Transfer Time</th>\n<th>Size and Type</th>\n<th>Volblocksize</th>\n<th>Number of Files</th>\n<th>Average File Size</th>\n<th>Average Speed (MB/s)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>0:13</td>\n<td>6.2 GB zip file</td>\n<td>64k</td>\n<td>1</td>\n<td>6.2 GB</td>\n<td>477.54</td>\n</tr>\n<tr>\n<td>0:13</td>\n<td>6.2 GB zip file</td>\n<td>8k</td>\n<td>1</td>\n<td>6.2 GB</td>\n<td>477.54</td>\n</tr>\n<tr>\n<td>1:38</td>\n<td>6.3 GB EverQuest folder</td>\n<td>64k</td>\n<td>18535</td>\n<td>~350 KB</td>\n<td>64.29</td>\n</tr>\n<tr>\n<td>1:55</td>\n<td>6.3 GB EverQuest folder</td>\n<td>8k</td>\n<td>18535</td>\n<td>~350 KB</td>\n<td>54.74</td>\n</tr>\n<tr>\n<td>1:24</td>\n<td>8.5 GB Resident Evil 5</td>\n<td>64k</td>\n<td>13692</td>\n<td>~640 KB</td>\n<td>101.19</td>\n</tr>\n<tr>\n<td>1:37</td>\n<td>8.5 GB Resident Evil 5</td>\n<td>8k</td>\n<td>13692</td>\n<td>~640 KB</td>\n<td>87.63</td>\n</tr>\n<tr>\n<td>2:18</td>\n<td>29.1 GB raw videos</td>\n<td>64k</td>\n<td>2</td>\n<td>14.55 GB</td>\n<td>210.76</td>\n</tr>\n<tr>\n<td>2:31</td>\n<td>29.1 GB raw videos</td>\n<td>8k</td>\n<td>2</td>\n<td>14.55 GB</td>\n<td>193.69</td>\n</tr>\n</tbody>\n</table>\n<p>These results were the opposite of what I expected.  I would have expected 8k volblocksize to be faster for the 2 game folders, which contain a ridiculous number of tiny files.  I would also expect the difference to be larger in the raw video transfers.  Let's test more.</p>\n<p>Crystaldiskmark works on network shares, so I tried that.</p>\n<p>8k:<br>\n<picture><source type=\"image/avif\" srcset=\"https://stinky.blog/img/T-LJg0XmsS-482.avif 482w\"><source type=\"image/webp\" srcset=\"https://stinky.blog/img/T-LJg0XmsS-482.webp 482w\"><img alt=\"8k crystalbenchmark\" loading=\"lazy\" decoding=\"async\" src=\"https://stinky.blog/img/T-LJg0XmsS-482.png\" width=\"482\" height=\"352\"></picture></p>\n<p>64k:<br>\n<picture><source type=\"image/avif\" srcset=\"https://stinky.blog/img/qzUq7bzt-Z-482.avif 482w\"><source type=\"image/webp\" srcset=\"https://stinky.blog/img/qzUq7bzt-Z-482.webp 482w\"><img alt=\"64k crystalbenchmark\" loading=\"lazy\" decoding=\"async\" src=\"https://stinky.blog/img/qzUq7bzt-Z-482.png\" width=\"482\" height=\"352\"></picture></p>\n<p>The speed increase for 1M operations makes sense to me when switching to 64k volblocksize.  The <strong>54%</strong> speed increase in 4k operations makes less sense to me.  These results align with the benchmarks on the 4 spinning disks in the last post, but they are still surprising to me!</p>\n<h2 id=\"what-have-i-learned-so-far\" tabindex=\"-1\">What have I learned so far? <a class=\"header-anchor\" href=\"https://stinky.blog/blog/zfs-bench2/zfs-volblocksize-round-2/\">#</a></h2>\n<p>Well, it's still pretty confusing.  64k seems to be universally faster than 8k, but probably causes a decent amount of write amplification for small writes typical of VM workloads.</p>\n<p>After all this testing, I am getting interested in possibly moving away from the fileserver-in-a-VM setup.  It has been pretty a pretty elegant solution, being able to backup, restore, and migrate the entire fileserver so quickly and easily.  I think I can still get most of the same functionality with a plain ZFS dataset mounted in a container, using zfs send/receive to back it up to the Proxmox Backup Server.  It can probably be automated pretty easily with a script and be faster and better than what I'm doing.</p>\n<p>This has been pretty fun to learn so far!  Switching up my approach will allow me to learn even more about zfs snapshots and how to manage them. It will also reduce backup and restore times even further.  Currently, the backup server relies on dirty-pages to know which files have changed for each backup.  If the VM has been restarted (or is currently offline), that means it still has to scan the full zvolume!  Excited to set up a container and start testing it soon.</p>\n",
			"date_published": "2024-03-21T00:00:00Z"
		}
		,
		{
			"id": "https://stinky.blog/blog/second-brain-activated/",
			"url": "https://stinky.blog/blog/second-brain-activated/",
			"title": "Second Brain activated",
			"content_html": "<h2 id=\"second-brain\" tabindex=\"-1\">Second Brain <a class=\"header-anchor\" href=\"https://stinky.blog/blog/second-brain-activated/\">#</a></h2>\n<p>I took calculus in '22.  Today, I wouldn't be able to find the derivative of a constant.  It's the same story with many things that I have learned over the years.  New info comes into the brain, old info gets dumped out.  That is something that I would like to change!  I want to remember stuff.</p>\n<p>Since embarking on this career change, information is coming at me at light speed.  Learning new things at work, studying for certifications, taking college classes, and homelabbing has my brain hitting its storage quota.  I would like a way to quickly document things and reference them later.  The method needs to be easy and fun, or else I won't stick with it.  Enter the second brain.</p>\n<p>After watching <a href=\"https://www.youtube.com/watch?v=zIGJ8NTHF4k&amp;t=3731s\">this guy's video</a> and looking at <a href=\"https://mischavandenburg.com/\">his site</a>, I decided I want to do something similar.  I don't need to take it as far as him, but I think it is an awesome idea.</p>\n<h2 id=\"markdown\" tabindex=\"-1\">Markdown <a class=\"header-anchor\" href=\"https://stinky.blog/blog/second-brain-activated/\">#</a></h2>\n<p>The idea is to simply take notes in markdown format and associate them with tags.  Then, you can search through them instantly using a fuzzy finder.</p>\n<p>Writing the notes in markdown serves a couple of key functions:</p>\n<ul>\n<li>can take notes from the terminal extremely quickly - no excuse not to</li>\n<li>still easy to insert media</li>\n<li>files are tiny</li>\n<li>allows instant conversion to static web pages for my blog</li>\n<li>easily convertible to another format if I stop doing this second brain thing</li>\n</ul>\n<h2 id=\"fuzzy-finder\" tabindex=\"-1\">Fuzzy finder <a class=\"header-anchor\" href=\"https://stinky.blog/blog/second-brain-activated/\">#</a></h2>\n<p>To search my notes, <a href=\"https://github.com/Magnushhoie/fuz\">I will be using fuz</a>.</p>\n<p>launch fuz</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">fuz</code></pre>\n<p>enter search terms, CTRL+L to view in <strong>less</strong>, CTRL +O to view in <strong>vim</strong></p>\n<h2 id=\"the-blog\" tabindex=\"-1\">The blog <a class=\"header-anchor\" href=\"https://stinky.blog/blog/second-brain-activated/\">#</a></h2>\n<p>In addition to using the fuzzy finder to search my notes locally, I want them to be available to me anywhere.  I found my old wordpress blog very handy for looking at my own tutorials to remember how I configured something or linking them to a friend.</p>\n<p>To make that super easy, I just store all the notes in a local github repo on my machine and use eleventy to generate static pages from them, which I explain in <a href=\"https://stinky.blog/blog/adios-wordpress/\">this post</a>.</p>\n<p>Having to write all the front matter for each new post and then generate the static pages, generate the search index, and then push that to github is a lot of steps for simple note-taking.  So I automated creating a new post <a href=\"https://stinky.blog/blog/create-new-post-script/\">with this script</a> and the page/index generation and github pushing with the script at the <a href=\"https://stinky.blog/blog/adios-wordpress/\">bottom of this page</a>.</p>\n",
			"date_published": "2024-03-17T00:00:00Z"
		}
		,
		{
			"id": "https://stinky.blog/blog/rhcsa/find/",
			"url": "https://stinky.blog/blog/rhcsa/find/",
			"title": "find",
			"content_html": "<h2 id=\"basic-usage\" tabindex=\"-1\">Basic usage <a class=\"header-anchor\" href=\"https://stinky.blog/blog/rhcsa/find/\">#</a></h2>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">find</span> <span class=\"token punctuation\">[</span>where<span class=\"token punctuation\">]</span> <span class=\"token punctuation\">[</span>options<span class=\"token punctuation\">]</span> <span class=\"token punctuation\">[</span>what<span class=\"token punctuation\">]</span></code></pre>\n<p>find all mp3 files in /mnt/media:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">find</span> /mnt/media <span class=\"token parameter variable\">-name</span> <span class=\"token string\">\"*.mp3\"</span></code></pre>\n<p>-type f = files,  d = directories</p>\n<p>mute errors for searching /:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">find</span> / <span class=\"token parameter variable\">-name</span> <span class=\"token string\">\"hosts\"</span> <span class=\"token operator\"><span class=\"token file-descriptor important\">2</span>></span> /dev/null</code></pre>\n<h2 id=\"extra-options\" tabindex=\"-1\">Extra options <a class=\"header-anchor\" href=\"https://stinky.blog/blog/rhcsa/find/\">#</a></h2>\n<p>find files modified within the last X days:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">find</span> /var/log <span class=\"token parameter variable\">-type</span> f <span class=\"token parameter variable\">-mtime</span> <span class=\"token parameter variable\">-1</span></code></pre>\n<p>find files modified more than X days ago:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">find</span> /var/log <span class=\"token parameter variable\">-type</span> f <span class=\"token parameter variable\">-mtime</span> +30</code></pre>\n<p>find files of a certain size (+/-):</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">find</span> /mnt/media <span class=\"token parameter variable\">-type</span> f <span class=\"token parameter variable\">-size</span> +1G</code></pre>\n<p>find files by permissions:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">find</span> /home <span class=\"token parameter variable\">-type</span> f <span class=\"token parameter variable\">-perm</span> 0777</code></pre>\n<h2 id=\"executing-commands-on-files\" tabindex=\"-1\">Executing commands on files <a class=\"header-anchor\" href=\"https://stinky.blog/blog/rhcsa/find/\">#</a></h2>\n<p>find files and move them somewhere:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">find</span> <span class=\"token builtin class-name\">.</span> <span class=\"token parameter variable\">-type</span> f <span class=\"token parameter variable\">-name</span> <span class=\"token string\">\"*.md\"</span> <span class=\"token parameter variable\">-exec</span> <span class=\"token function\">cp</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span> ~/notes/ <span class=\"token punctuation\">\\</span><span class=\"token punctuation\">;</span></code></pre>\n<p>{} = placeholder for what find is finding\n; = ; ends the command, needs escape character</p>\n<p>use xargs instead of exec:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">find</span> /etc <span class=\"token parameter variable\">-type</span> f <span class=\"token operator\">|</span> <span class=\"token function\">xargs</span> <span class=\"token function\">grep</span> <span class=\"token string\">\"127.0.0.1\"</span> <span class=\"token operator\"><span class=\"token file-descriptor important\">2</span>></span> /dev/null</code></pre>\n<p>xargs will batch the input before executing, -exec will run the command once for each input item</p>\n",
			"date_published": "2024-03-17T00:00:00Z"
		}
		,
		{
			"id": "https://stinky.blog/blog/bash-config/",
			"url": "https://stinky.blog/blog/bash-config/",
			"title": "Bash config",
			"content_html": "<h2 id=\"global-vs-user\" tabindex=\"-1\">Global vs user <a class=\"header-anchor\" href=\"https://stinky.blog/blog/bash-config/\">#</a></h2>\n<p>Global configs in /etc affect all users.  Includes /etc/profile and /etc/bash.bashrc</p>\n<p>/etc/profile is not bash specific -- contains system-wide environment variables and startup config for login shells</p>\n<p>/etc/bash.bashrc is the global config for non-login bash shells.</p>\n<p>User-specific configs are located in the users home folder -- .bashrc and .bash_profile</p>\n<p>These are copied from /etc/skel upon user creation</p>\n",
			"date_published": "2024-03-17T00:00:00Z"
		}
		,
		{
			"id": "https://stinky.blog/blog/rhcsa/shell-expansion/",
			"url": "https://stinky.blog/blog/rhcsa/shell-expansion/",
			"title": "Shell expansion",
			"content_html": "<h2 id=\"globbing\" tabindex=\"-1\">Globbing <a class=\"header-anchor\" href=\"https://stinky.blog/blog/rhcsa/shell-expansion/\">#</a></h2>\n<p>Expand filenames with wildcards.  * represents any pattern.  ? represents any single character.</p>\n<p>list everything:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">ls</span> *</code></pre>\n<p>list things that start with &quot;a&quot; and are at least 2 characters long:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">ls</span> a?*</code></pre>\n<p>list things that begin with lowercase a - e:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">ls</span> <span class=\"token punctuation\">[</span>a-e<span class=\"token punctuation\">]</span>*</code></pre>\n<h2 id=\"braces\" tabindex=\"-1\">Braces <a class=\"header-anchor\" href=\"https://stinky.blog/blog/rhcsa/shell-expansion/\">#</a></h2>\n<p>Perform this action on 1 through 9:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">touch</span> file<span class=\"token punctuation\">{</span><span class=\"token number\">1</span><span class=\"token punctuation\">..</span><span class=\"token number\">9</span><span class=\"token punctuation\">}</span> </code></pre>\n<p>Perform this action on all these terms:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">useradd</span> <span class=\"token punctuation\">{</span>lisa,linda,anna<span class=\"token punctuation\">}</span></code></pre>\n<h2 id=\"substitution\" tabindex=\"-1\">Substitution <a class=\"header-anchor\" href=\"https://stinky.blog/blog/rhcsa/shell-expansion/\">#</a></h2>\n<p>Search for the output of the command:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">ls</span> <span class=\"token parameter variable\">-l</span> <span class=\"token variable\"><span class=\"token variable\">$(</span><span class=\"token function\">which</span> <span class=\"token function\">ls</span><span class=\"token variable\">)</span></span></code></pre>\n<p>Use variable contents in command:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token builtin class-name\">echo</span> <span class=\"token environment constant\">$PATH</span></code></pre>\n",
			"date_published": "2024-03-16T00:00:00Z"
		}
		,
		{
			"id": "https://stinky.blog/blog/rhcsa/shell-escaping/",
			"url": "https://stinky.blog/blog/rhcsa/shell-escaping/",
			"title": "Shell escaping",
			"content_html": "<p>Special characters must be escaped to prevent the shell from interpreting them as part of the script/command.</p>\n<p><strong>Double quotes</strong> &quot;...&quot; suppress globbing and shell expansion but still allow command and variable substitutions.</p>\n<p><strong>Single quotes</strong> '...' suppress all special characters.</p>\n<p><strong>Backslashes</strong> &quot; \\ &quot; suppress only the character following the slash.</p>\n",
			"date_published": "2024-03-16T00:00:00Z"
		}
		,
		{
			"id": "https://stinky.blog/blog/create-new-post-script/",
			"url": "https://stinky.blog/blog/create-new-post-script/",
			"title": "Create New Post script",
			"content_html": "<h2 id=\"quickly-create-new-posts\" tabindex=\"-1\">Quickly create new posts <a class=\"header-anchor\" href=\"https://stinky.blog/blog/create-new-post-script/\">#</a></h2>\n<p>Made this little script to generate the front matter for new blog posts and open them in the editor.  Estimated to save dozens of seconds over the course of my lifetime</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token shebang important\">#!/bin/bash</span>\n\n<span class=\"token comment\">#gather post info</span>\n\n<span class=\"token builtin class-name\">echo</span> <span class=\"token string\">\"Post title?\"</span>\n<span class=\"token builtin class-name\">read</span> title\n\n<span class=\"token builtin class-name\">echo</span> <span class=\"token string\">\"Post description?\"</span>\n<span class=\"token builtin class-name\">read</span> description\n\n<span class=\"token assign-left variable\">current_date</span><span class=\"token operator\">=</span><span class=\"token variable\"><span class=\"token variable\">$(</span><span class=\"token function\">date</span> +%Y-%m-%d<span class=\"token variable\">)</span></span>\n\n<span class=\"token builtin class-name\">echo</span> <span class=\"token string\">\"Post tags? (one or more, comma separated, like, this)\"</span>\n<span class=\"token builtin class-name\">read</span> tags\n\n<span class=\"token comment\">#clean up tags</span>\n\n<span class=\"token assign-left variable\">tidytags</span><span class=\"token operator\">=</span><span class=\"token variable\"><span class=\"token variable\">$(</span><span class=\"token builtin class-name\">echo</span> $tags <span class=\"token operator\">|</span> <span class=\"token function\">sed</span> <span class=\"token string\">\"s/, /<span class=\"token entity\" title=\"\\\\\">\\\\</span>n  - /g\"</span><span class=\"token variable\">)</span></span>\n\n<span class=\"token comment\">#generate post metadata</span>\n\n<span class=\"token assign-left variable\">fmatter</span><span class=\"token operator\">=</span><span class=\"token string\">\"---\ntitle: <span class=\"token entity\" title=\"\\&quot;\">\\\"</span><span class=\"token variable\">$title</span><span class=\"token entity\" title=\"\\&quot;\">\\\"</span>\ndescription: <span class=\"token entity\" title=\"\\&quot;\">\\\"</span><span class=\"token variable\">$description</span><span class=\"token entity\" title=\"\\&quot;\">\\\"</span>\ndate: <span class=\"token variable\">$current_date</span>\ntags:\n  - <span class=\"token variable\">$tidytags</span>\n---\n\"</span>\n<span class=\"token comment\">#convert title to filename</span>\n\n<span class=\"token assign-left variable\">filename</span><span class=\"token operator\">=</span><span class=\"token variable\"><span class=\"token variable\">$(</span><span class=\"token builtin class-name\">echo</span> $title <span class=\"token operator\">|</span> <span class=\"token function\">tr</span> <span class=\"token string\">'[:upper:]'</span> <span class=\"token string\">'[:lower:]'</span> <span class=\"token operator\">|</span> <span class=\"token function\">tr</span> <span class=\"token string\">' '</span> <span class=\"token string\">'-'</span><span class=\"token variable\">)</span></span>.md\n\n<span class=\"token comment\">#write metadata to filename</span>\n<span class=\"token builtin class-name\">echo</span> <span class=\"token string\">\"<span class=\"token variable\">$fmatter</span>\"</span> <span class=\"token operator\">></span> <span class=\"token string\">\"./content/blog/<span class=\"token variable\">$filename</span>\"</span>\n\n<span class=\"token comment\">#open vim @ filename</span>\n<span class=\"token function\">vim</span> <span class=\"token string\">\"./content/blog/<span class=\"token variable\">$filename</span>\"</span></code></pre>\n",
			"date_published": "2024-03-11T00:00:00Z"
		}
		,
		{
			"id": "https://stinky.blog/blog/rhcsa/vim/",
			"url": "https://stinky.blog/blog/rhcsa/vim/",
			"title": "vim",
			"content_html": "<p><strong>vimtutor</strong> to launch tutorial</p>\n<h2 id=\"general\" tabindex=\"-1\">General <a class=\"header-anchor\" href=\"https://stinky.blog/blog/rhcsa/vim/\">#</a></h2>\n<p>Starts in <strong>command mode</strong>, press <strong>i</strong> for <strong>insert mode</strong> or <strong>a</strong> for <strong>append mode</strong></p>\n<p>Escape to re-enter command mode</p>\n<p><strong>:w</strong> --  Save file</p>\n<p><strong>:q</strong> -- Quit</p>\n<p><strong>:wq</strong> -- Save and quit</p>\n<p><strong>:q!</strong> --  Quit without saving</p>\n<p><strong>o</strong> -- enters insert mode on a new line</p>\n<h2 id=\"text-operations\" tabindex=\"-1\">Text Operations <a class=\"header-anchor\" href=\"https://stinky.blog/blog/rhcsa/vim/\">#</a></h2>\n<p><strong>dd</strong> -- delete current line</p>\n<p><strong>yy</strong> -- copy current line</p>\n<p><strong>p</strong> -- paste current line</p>\n<p><strong>u</strong> -- undo</p>\n<p><strong>ctrl+r</strong> -- redo</p>\n<p><strong>:%s/oldword/newword/g</strong> -- substitute phrase -- /g = all instances</p>\n<h2 id=\"visual-mode\" tabindex=\"-1\">Visual mode <a class=\"header-anchor\" href=\"https://stinky.blog/blog/rhcsa/vim/\">#</a></h2>\n<p><strong>v</strong> --  enter visual mode</p>\n<p>highlight text starting from current cursor position then copy/paste/delete/etc</p>\n<h2 id=\"navigate\" tabindex=\"-1\">Navigate <a class=\"header-anchor\" href=\"https://stinky.blog/blog/rhcsa/vim/\">#</a></h2>\n<p><strong>gg</strong> -- top of document</p>\n<p><strong>G</strong> -- end of document</p>\n<p><strong>/word</strong> -- search for &quot;word&quot;</p>\n<p><strong>?word</strong> -- search backwards for &quot;word&quot;</p>\n<p><strong>^</strong> -- move to beginning of line</p>\n<p><strong>$</strong> -- move to end of line</p>\n<p><strong>w</strong> -- move to next word</p>\n<h2 id=\"display\" tabindex=\"-1\">Display <a class=\"header-anchor\" href=\"https://stinky.blog/blog/rhcsa/vim/\">#</a></h2>\n<p><strong>:se numbers</strong> -- show line numbers</p>\n<hr>\n<blockquote>\n<p><em>this page written proudly in nano</em></p>\n</blockquote>\n",
			"date_published": "2024-03-10T00:00:00Z"
		}
		,
		{
			"id": "https://stinky.blog/blog/rhcsa/stds/",
			"url": "https://stinky.blog/blog/rhcsa/stds/",
			"title": "stdin, stdout, stderr",
			"content_html": "<h2 id=\"redirection\" tabindex=\"-1\">Redirection <a class=\"header-anchor\" href=\"https://stinky.blog/blog/rhcsa/stds/\">#</a></h2>\n<p>Write (or overwrite) stdout to file:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">thing <span class=\"token operator\">></span> place</code></pre>\n<p>Append stdout to file:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">thing <span class=\"token operator\">>></span> place</code></pre>\n<p>Write/append errors to a file:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">thing <span class=\"token operator\"><span class=\"token file-descriptor important\">2</span>></span> or <span class=\"token operator\"><span class=\"token file-descriptor important\">2</span>>></span> place</code></pre>\n",
			"date_published": "2024-03-10T00:00:00Z"
		}
		,
		{
			"id": "https://stinky.blog/blog/rhcsa/man/",
			"url": "https://stinky.blog/blog/rhcsa/man/",
			"title": "man",
			"content_html": "<h2 id=\"sections\" tabindex=\"-1\">Sections <a class=\"header-anchor\" href=\"https://stinky.blog/blog/rhcsa/man/\">#</a></h2>\n<ol>\n<li>executables / shell cmds</li>\n<li>system calls</li>\n<li>library calls</li>\n<li>special files (/dev)</li>\n<li>file formats / conventions</li>\n<li>games</li>\n<li>misc</li>\n<li>sys admin / root</li>\n<li>kernel routines</li>\n</ol>\n<p>To search for a command in a particular section, <strong>man # command</strong></p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">man</span> <span class=\"token number\">5</span> <span class=\"token function\">passwd</span></code></pre>\n<p>man returns the first section number for a given command.  to see all sections:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">man</span> <span class=\"token parameter variable\">-a</span> <span class=\"token function\">passwd</span></code></pre>\n<h2 id=\"navigation\" tabindex=\"-1\">Navigation <a class=\"header-anchor\" href=\"https://stinky.blog/blog/rhcsa/man/\">#</a></h2>\n<p>Use / to search</p>\n<p>spacebar / pgdown / pgup to scroll</p>\n<h2 id=\"searching\" tabindex=\"-1\">Searching <a class=\"header-anchor\" href=\"https://stinky.blog/blog/rhcsa/man/\">#</a></h2>\n<p>Search the NAME field:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">man</span> <span class=\"token parameter variable\">-k</span> <span class=\"token punctuation\">[</span>keyword<span class=\"token punctuation\">]</span></code></pre>\n<p>or</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">apropos</span> <span class=\"token punctuation\">[</span>keyword<span class=\"token punctuation\">]</span></code></pre>\n<p>n for next result, p for previous</p>\n<h2 id=\"mandb\" tabindex=\"-1\">mandb <a class=\"header-anchor\" href=\"https://stinky.blog/blog/rhcsa/man/\">#</a></h2>\n<p>Search index needs to be built  with <strong>mandb</strong> command (cronjob or manually)</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">sudo</span> mandb</code></pre>\n<p>search returns &quot;nothing appropriate&quot; ? run <strong>mandb</strong></p>\n",
			"date_published": "2024-03-10T00:00:00Z"
		}
		,
		{
			"id": "https://stinky.blog/blog/rhcsa/bash-shortcuts/",
			"url": "https://stinky.blog/blog/rhcsa/bash-shortcuts/",
			"title": "bash shortcuts",
			"content_html": "<h2 id=\"ctrl\" tabindex=\"-1\">Ctrl <a class=\"header-anchor\" href=\"https://stinky.blog/blog/rhcsa/bash-shortcuts/\">#</a></h2>\n<table>\n<thead>\n<tr>\n<th>Shortcut</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Ctrl + D</strong></td>\n<td>End of file</td>\n</tr>\n<tr>\n<td><strong>Ctrl + C</strong></td>\n<td>Interrupt a command</td>\n</tr>\n<tr>\n<td><strong>Ctrl + Z</strong></td>\n<td>Suspend a command</td>\n</tr>\n<tr>\n<td><strong>Ctrl + A</strong></td>\n<td>Move to start of line</td>\n</tr>\n<tr>\n<td><strong>Ctrl + E</strong></td>\n<td>Move to end of line</td>\n</tr>\n<tr>\n<td><strong>Ctrl + K</strong></td>\n<td>Cut text to end of line</td>\n</tr>\n<tr>\n<td><strong>Ctrl + U</strong></td>\n<td>Cut text to start of line</td>\n</tr>\n<tr>\n<td><strong>Ctrl + Y</strong></td>\n<td>Paste the last cut text</td>\n</tr>\n<tr>\n<td><strong>Ctrl + R</strong></td>\n<td>Search history backwards</td>\n</tr>\n<tr>\n<td><strong>Ctrl + L</strong></td>\n<td>Clear the screen</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"alt\" tabindex=\"-1\">Alt <a class=\"header-anchor\" href=\"https://stinky.blog/blog/rhcsa/bash-shortcuts/\">#</a></h2>\n<table>\n<thead>\n<tr>\n<th>Shortcut</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Alt + b</strong></td>\n<td>Move back one word</td>\n</tr>\n<tr>\n<td><strong>Alt + f</strong></td>\n<td>Move forward one word</td>\n</tr>\n<tr>\n<td><strong>Alt + d</strong></td>\n<td>Delete word right of the cursor</td>\n</tr>\n<tr>\n<td><strong>Alt + Backspace</strong></td>\n<td>Delete word left of the cursor</td>\n</tr>\n<tr>\n<td><strong>Alt + &lt;</strong></td>\n<td>Move to the beginning of the history</td>\n</tr>\n<tr>\n<td><strong>Alt + &gt;</strong></td>\n<td>Move to the end of the history</td>\n</tr>\n<tr>\n<td><strong>Alt + t</strong></td>\n<td>Swap the current word with the previous</td>\n</tr>\n<tr>\n<td><strong>Alt + u</strong></td>\n<td>Uppercase word from cursor to end of word</td>\n</tr>\n<tr>\n<td><strong>Alt + l</strong></td>\n<td>Lowercase word from cursor to end of word</td>\n</tr>\n<tr>\n<td><strong>Alt + c</strong></td>\n<td>Capitalize the word</td>\n</tr>\n<tr>\n<td><strong>Alt + r</strong></td>\n<td>Revert any changes to a command you've pulled from history</td>\n</tr>\n</tbody>\n</table>\n",
			"date_published": "2024-03-10T00:00:00Z"
		}
		,
		{
			"id": "https://stinky.blog/blog/rhcsa/bash-history/",
			"url": "https://stinky.blog/blog/rhcsa/bash-history/",
			"title": "bash history",
			"content_html": "<h2 id=\"history\" tabindex=\"-1\">History <a class=\"header-anchor\" href=\"https://stinky.blog/blog/rhcsa/bash-history/\">#</a></h2>\n<p>bash keeps all recently used commands in ~./bash_history</p>\n<p>To see all recently used bash commands:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">history</span></code></pre>\n<p><strong>Ctrl + r</strong> To search history</p>\n<p>To repeat a command by its line # on 'history':</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token operator\">!</span>nn</code></pre>\n<p>Repeat last command that starts with letter a:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token operator\">!</span>a</code></pre>\n<p>Repeat last command with sudo:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">sudo</span> <span class=\"token operator\">!</span><span class=\"token operator\">!</span></code></pre>\n<h2 id=\"history-settings\" tabindex=\"-1\">History settings <a class=\"header-anchor\" href=\"https://stinky.blog/blog/rhcsa/bash-history/\">#</a></h2>\n<p>Set two environment variables $HISTSIZE and $HISTFILESIZE</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token builtin class-name\">echo</span> <span class=\"token number\">500</span> <span class=\"token environment constant\">$HISTSIZE</span> or <span class=\"token environment constant\">$HISTFILESIZE</span></code></pre>\n<p>to make permanent, add to ~/.bashrc</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\"><span class=\"token environment constant\">HISTFILESIZE</span></span><span class=\"token operator\">=</span><span class=\"token number\">500</span>\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\"><span class=\"token environment constant\">HISTSIZE</span></span><span class=\"token operator\">=</span><span class=\"token number\">500</span></code></pre>\n<p>Write current history to history file:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">history</span> <span class=\"token parameter variable\">-w</span></code></pre>\n<p>Clear current history:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">history</span> <span class=\"token parameter variable\">-c</span></code></pre>\n<p>Clear specific line:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">history</span> <span class=\"token parameter variable\">-d</span> nn</code></pre>\n<p>History file is not merged until terminal exit</p>\n",
			"date_published": "2024-03-10T00:00:00Z"
		}
		,
		{
			"id": "https://stinky.blog/blog/zfs-bench/",
			"url": "https://stinky.blog/blog/zfs-bench/",
			"title": "ZFS Volblocksize for VM Workloads",
			"content_html": "<p>I store all of my VMs on ZFS pools.  On Proxmox, VMs stored on ZFS pools will use zvols by default, rather than a disk file in a dataset. Proxmox zvols use a default volblocksize of 8k.  What the heck is a zvol, and what is the impact on storage performance?</p>\n<p><strong>Zvols</strong> present a virtual block device to the VM, like a physical disk.  It sounds pretty cool, but it comes with some caveats.  Zvols use a <em>volblocksize</em> rather than a recordsize or a block size.  Selecting the wrong volblocksize for your workload can result in extreme write amplification, increased drive wear, and terrible performance.</p>\n<p><strong>Volblocksize</strong> represents the <em>minimum</em> amount of data that can be written to a zvol.  This is the opposite of recordsize, which refers to the maximum.  Writing a 1kb file to a zpool with a recordsize of 128k is no problem -- ZFS will simply write 1k. The same 1k write on a zvol with volblocksize of 128k will cause 128k of data to be written.  That's a write amplification of <strong>128x</strong>.  No bueno!</p>\n<p>A similar situation occurs in reverse.  You have a 128k volblocksize and you need to read 1k.  ZFS must read the whole 128k block to return your 1k data.  This can greatly increase latency and reduce IOPs.</p>\n<p>It gets even worse if you're calculating parity -- arrays with certain drive configurations can lose 50% or more of their total usable space to metadata when block size is set too low.  Look for posts discussing &quot;padding overhead&quot; or <a href=\"https://www.delphix.com/blog/zfs-raidz-stripe-width-or-how-i-learned-stop-worrying-and-love-raidz\">posts like this</a> for more info.</p>\n<p>I was hoping that the perfect volblocksize would be just a google search away... but it looks like it's gonna be more complicated than that!  The volblocksize should precisely match the workload, 16k for databases which perform 16k writes, for example.  I'm not sure exactly what that would be for my typical usage.  So, my goal here is to just to learn what I can about how ZFS interacts with zvols, starting with some simple tests.</p>\n<h2 id=\"testing-methodology-round-1\" tabindex=\"-1\">Testing Methodology - Round 1 <a class=\"header-anchor\" href=\"https://stinky.blog/blog/zfs-bench/\">#</a></h2>\n<p>I'll be using a striped mirror containing 4x 12TB drives.  The underlying pool has ashift=12, compression=LZ4, recordsize=128k.  I am testing inside a Debian VM with ext4 filesystem, 4k blocks, cache=none.</p>\n<p>To test each volblocksize, I am simply moving the virtual disk off of the pool, resetting the volblocksize, and then moving the virtual disk back to the pool.  (The data needs to be written again in order for the new volblocksize to take effect.)</p>\n<p>For round one, I would like to find the extremes -- just to get some idea of the relationship between these values.</p>\n<p>First, I used fio to test random writes of 4k and 1M blocks at queue depth 1.  I ran both tests on volblocksizes 8k, 16k, 32k, and 64k. sync=disabled</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">fio <span class=\"token parameter variable\">--name</span><span class=\"token operator\">=</span>random-write <span class=\"token parameter variable\">--ioengine</span><span class=\"token operator\">=</span>posixaio <span class=\"token parameter variable\">--rw</span><span class=\"token operator\">=</span>randwrite <span class=\"token parameter variable\">--bs</span><span class=\"token operator\">=</span>1M <span class=\"token parameter variable\">--size</span><span class=\"token operator\">=</span>4g <span class=\"token parameter variable\">--numjobs</span><span class=\"token operator\">=</span><span class=\"token number\">1</span> <span class=\"token parameter variable\">--iodepth</span><span class=\"token operator\">=</span><span class=\"token number\">1</span> <span class=\"token parameter variable\">--runtime</span><span class=\"token operator\">=</span><span class=\"token number\">60</span> <span class=\"token parameter variable\">--time_based</span> <span class=\"token parameter variable\">--end_fsync</span><span class=\"token operator\">=</span><span class=\"token number\">1</span></code></pre>\n<br>\n<h2 id=\"4k-random-writes\" tabindex=\"-1\">4k random writes: <a class=\"header-anchor\" href=\"https://stinky.blog/blog/zfs-bench/\">#</a></h2>\n<table>\n<thead>\n<tr>\n<th>Volblocksize</th>\n<th>Block Size</th>\n<th>IOPS</th>\n<th>Bandwidth (MiB/s)</th>\n<th>Average Latency (s)</th>\n<th>99th Percentile Latency (s)</th>\n<th>Disk Utilization (%)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>8K</td>\n<td>4K</td>\n<td>15.7k</td>\n<td>61.2</td>\n<td>41.74</td>\n<td>99</td>\n<td>86.15</td>\n</tr>\n<tr>\n<td>16K</td>\n<td>4K</td>\n<td>18.1k</td>\n<td>70.8</td>\n<td>32.89</td>\n<td>93</td>\n<td>78.41</td>\n</tr>\n<tr>\n<td>32K</td>\n<td>4K</td>\n<td>19.7k</td>\n<td>76.8</td>\n<td>33.55</td>\n<td>105</td>\n<td>79.44</td>\n</tr>\n<tr>\n<td>64K</td>\n<td>4K</td>\n<td>25.1k</td>\n<td>97.9</td>\n<td>35.81</td>\n<td>126</td>\n<td>55.38</td>\n</tr>\n</tbody>\n</table>\n<p>These results were surprising to me!  Switching from 8k to 64k volblocksize, we see a 60% increase in throughput and a huge drop in iowait.  There is a 60% increase in IOPs, as well.</p>\n<p>I will have to run some more detailed tests here, but I suspect these huge gains may come with huge penalties in other areas.  Namely, random reads that miss the ARC, or writes that require read/modify/write.  Will have to figure out how to test that later.</p>\n<br>  \n<h2 id=\"1m-random-writes\" tabindex=\"-1\">1M random writes: <a class=\"header-anchor\" href=\"https://stinky.blog/blog/zfs-bench/\">#</a></h2>\n<table>\n<thead>\n<tr>\n<th>Volblocksize</th>\n<th>Block Size</th>\n<th>IOPS</th>\n<th>Bandwidth (MiB/s)</th>\n<th>Average Latency (s)</th>\n<th>99th Percentile Latency (s)</th>\n<th>Disk Utilization (%)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>8K</td>\n<td>1M</td>\n<td>163</td>\n<td>164</td>\n<td>3136.59</td>\n<td>217056</td>\n<td>93.79</td>\n</tr>\n<tr>\n<td>16K</td>\n<td>1M</td>\n<td>177</td>\n<td>178</td>\n<td>3638.31</td>\n<td>125305</td>\n<td>90.54</td>\n</tr>\n<tr>\n<td>32K</td>\n<td>1M</td>\n<td>311</td>\n<td>312</td>\n<td>2207.24</td>\n<td>143655</td>\n<td>89.67</td>\n</tr>\n<tr>\n<td>64K</td>\n<td>1M</td>\n<td>338</td>\n<td>339</td>\n<td>1933.32</td>\n<td>43779</td>\n<td>93.11</td>\n</tr>\n</tbody>\n</table>\n<p>Same story here!  106% increase in random write speed switching from 8k volblocksize to 64k.   107% increase in IOPs.  Much larger reduction in disk latency here than in the 4k tests.</p>\n<p>I would bet we get the same trade-off here, issues with small random reads and modifying files in place.  Someone give me a trail of breadcrumbs for how to test that!</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://stinky.blog/img/2gS10ltJ7R-594.avif 594w\"><source type=\"image/webp\" srcset=\"https://stinky.blog/img/2gS10ltJ7R-594.webp 594w\"><img alt=\"line graph\" loading=\"lazy\" decoding=\"async\" src=\"https://stinky.blog/img/2gS10ltJ7R-594.jpeg\" width=\"594\" height=\"319\"></picture></p>\n<p>Looking forward to round 2.  Next time, I'd like to find a way to see how much amplification is going on here, as well as how badly this is affecting reads outside of ARC.</p>\n<p>Would love some feedback on my methodology and some pointers!  More fun to learn with friends.  brianm88 @ gmail.com or /dev/goat on Steam.</p>\n<p>Thanks for reading.  Happy homelabbing!</p>\n",
			"date_published": "2024-03-06T00:00:00Z"
		}
		,
		{
			"id": "https://stinky.blog/blog/backup-server/backup-server-build/",
			"url": "https://stinky.blog/blog/backup-server/backup-server-build/",
			"title": "Building a better backup server",
			"content_html": "<p>It's always exciting to get new homelab stuff!  Here's what I've been up to.</p>\n<p>My old Proxmox Backup Server has been running on a Thinkpad x270 with a 5TB external USB drive for a little over a year now.  It is installed alongside the hypervisor, with ZFS on the datastore.  It's been working great!  Backup times were not <em>that</em> bad, but restore times were really slow.</p>\n<p>I still use that node as a secondary backup server, which will clone the primary backup datastore daily.  I plan to move it to my mom's house and leave it connected via tailscale as part of my little &quot;3-2-1&quot; backup plan.</p>\n<p>I wanted to build a better, faster PBS server that can also double as a robust Proxmox node for other tasks.  I also wanted to do it cheap!  So I started hunting on ebay...</p>\n<h2 id=\"the-new-server\" tabindex=\"-1\">The new server <a class=\"header-anchor\" href=\"https://stinky.blog/blog/backup-server/backup-server-build/\">#</a></h2>\n<p>You already know I bought another Thinkstation.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://stinky.blog/img/zzH1bw69e7-400.avif 400w\"><source type=\"image/webp\" srcset=\"https://stinky.blog/img/zzH1bw69e7-400.webp 400w\"><img alt=\"Thinkstation P320\" loading=\"lazy\" decoding=\"async\" src=\"https://stinky.blog/img/zzH1bw69e7-400.jpeg\" width=\"400\" height=\"533\"></picture></p>\n<p>I bought a P320 Tower, little brother to the P330 SFF I already have. It came with an i7-7700k, 512gb nvme, and 32gb of ddr4.</p>\n<p>Here are the parts I was able to get and the prices:</p>\n<table>\n<thead>\n<tr>\n<th>Quantity</th>\n<th>Item</th>\n<th>Price</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>Thinkstation P320</td>\n<td>$163</td>\n</tr>\n<tr>\n<td>2</td>\n<td>12TB Toshiba MG07ACA12TEY (new)</td>\n<td>$100/each</td>\n</tr>\n<tr>\n<td>2</td>\n<td>12TB WD HUH721212AL (used)</td>\n<td>$90/each</td>\n</tr>\n<tr>\n<td>1</td>\n<td>32GB Timetec ddr4 2600</td>\n<td>$50</td>\n</tr>\n<tr>\n<td>1</td>\n<td>10gbe Intel X520 nic</td>\n<td>$20</td>\n</tr>\n<tr>\n<td>2</td>\n<td>Orico hot swap bay adapter 5.25&quot;</td>\n<td>$18</td>\n</tr>\n<tr>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n</tr>\n<tr>\n<td>Total</td>\n<td></td>\n<td>$649</td>\n</tr>\n</tbody>\n</table>\n<p>So for less than the cost of a decent NAS with no disks, I was able to get 48TBs, 10gbe, 64gb ram and a fairly strong kaby lake cpu.  One day when we reach a post-scarcity society, I'll swap to ECC memory and get more flash storage.</p>\n<h2 id=\"hardware\" tabindex=\"-1\">Hardware <a class=\"header-anchor\" href=\"https://stinky.blog/blog/backup-server/backup-server-build/\">#</a></h2>\n<p>Both the &quot;new&quot; drives and the &quot;used&quot; drives came in Dell hotswap bays, which I had to remove.<br>\n<picture><source type=\"image/avif\" srcset=\"https://stinky.blog/img/u6qDAQKe0l-400.avif 400w\"><source type=\"image/webp\" srcset=\"https://stinky.blog/img/u6qDAQKe0l-400.webp 400w\"><img alt=\"Dell drive caddy\" loading=\"lazy\" decoding=\"async\" src=\"https://stinky.blog/img/u6qDAQKe0l-400.jpeg\" width=\"400\" height=\"533\"></picture></p>\n<p>This case only has 2 slots for 3.5&quot; drives, so I slipped the little plastic Lenovo caddy on two of them.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://stinky.blog/img/DOZ-EKQ58A-400.avif 400w\"><source type=\"image/webp\" srcset=\"https://stinky.blog/img/DOZ-EKQ58A-400.webp 400w\"><img alt=\"Lenovo drive caddy\" loading=\"lazy\" decoding=\"async\" src=\"https://stinky.blog/img/DOZ-EKQ58A-400.jpeg\" width=\"400\" height=\"300\"></picture></p>\n<p>For the other two drives, I used the two hotswap bays from Amazon.  Very cool little devices for $18!</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://stinky.blog/img/6h_VGyvyih-400.avif 400w\"><source type=\"image/webp\" srcset=\"https://stinky.blog/img/6h_VGyvyih-400.webp 400w\"><img alt=\"Hot swap bay\" loading=\"lazy\" decoding=\"async\" src=\"https://stinky.blog/img/6h_VGyvyih-400.jpeg\" width=\"400\" height=\"300\"></picture></p>\n<p>Pretty tidy!  There is a garbage SSD free-floating around in there.  We'll chat more about that in the ZFS optimization post. (Foreshadowing:  awful SSDs make awful SLOG/L2Arc devices)</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://stinky.blog/img/6T6z6DWQvc-400.avif 400w\"><source type=\"image/webp\" srcset=\"https://stinky.blog/img/6T6z6DWQvc-400.webp 400w\"><img alt=\"Server internals with drives hooked up\" loading=\"lazy\" decoding=\"async\" src=\"https://stinky.blog/img/6T6z6DWQvc-400.jpeg\" width=\"400\" height=\"300\"></picture></p>\n<p>It looks pretty awesome with the drive bays now!  The lights are REALLY bright though, if that's not your thing.  Blue when powered on, red for activity.  It's like a police raid when the backups are running.</p>\n<p>Excuse the wires, had to plug in a monitor to troubleshoot (network cable was plugged into wrong port):</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://stinky.blog/img/8xnhi5QQGN-400.avif 400w\"><source type=\"image/webp\" srcset=\"https://stinky.blog/img/8xnhi5QQGN-400.webp 400w\"><img alt=\"Server rack with backup server installed\" loading=\"lazy\" decoding=\"async\" src=\"https://stinky.blog/img/8xnhi5QQGN-400.jpeg\" width=\"400\" height=\"533\"></picture></p>\n<h2 id=\"initial-config\" tabindex=\"-1\">Initial config <a class=\"header-anchor\" href=\"https://stinky.blog/blog/backup-server/backup-server-build/\">#</a></h2>\n<p>Pretty simple, just slapped Proxmox on it, installed Proxmox Backup Server alongside it.</p>\n<p>The ZFS pool is setup as a striped mirror, with two drives in each vdev. Ashift=12, compression=LZ4, recordsize=1M.</p>\n<h2 id=\"first-impressions\" tabindex=\"-1\">First impressions <a class=\"header-anchor\" href=\"https://stinky.blog/blog/backup-server/backup-server-build/\">#</a></h2>\n<p><picture><source type=\"image/avif\" srcset=\"https://stinky.blog/img/mtuSOuIa1e-400.avif 400w\"><source type=\"image/webp\" srcset=\"https://stinky.blog/img/mtuSOuIa1e-400.webp 400w\"><img alt=\"Backup speed\" loading=\"lazy\" decoding=\"async\" src=\"https://stinky.blog/img/mtuSOuIa1e-400.jpeg\" width=\"400\" height=\"290\"></picture></p>\n<p>Backups and restores are roughly ~10x faster!  Old backup server would write at about ~20MB/s.  Now backups are writing at 250MB/s+.  Reads are obviously much higher (~20 seconds to restore average 32GB linux VMs).  Live restores work great.  This node also has 8 times as much memory as the old x270 has, so I'm able to run a lot more VMs on it as well.  Pretty good deal!</p>\n<p>Very excited to delve deeper into ZFS and start testing my workload and optimizing the pool settings.</p>\n<p>I have been messing with recordsizes, volblocksizes, SLOG devices, and L2arc already!  The next post will contain some of my findings.</p>\n<p>Happy homelabbing!</p>\n",
			"date_published": "2024-03-05T00:00:00Z"
		}
		,
		{
			"id": "https://stinky.blog/blog/adios-wordpress/",
			"url": "https://stinky.blog/blog/adios-wordpress/",
			"title": "Adios Wordpress?",
			"content_html": "<p>Welcome to my first post on a static site.  Wordpress has been super cool, but I really wanted to try out something simpler and easier to deploy from the commandline.</p>\n<p>It has been a blast hosting the blog on the VPS and learning the ins-and-outs of securing the server, managing the certificates, and general wordpress admin stuff.  Wordpress plugins have been very awesome and easy to use, even the free ones.  However, it's just a ton of functionality that I don't really need.</p>\n<p>I watched a couple of youtube videos about hosting static sites on github pages with jekyll and other static site generators.  That led me to trying out a few of them before landing on this one, eleventy.</p>\n<p>To get this running, I created a github repository: username.github.io</p>\n<p>Then, I cloned the repo to my home folder</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">git</span> clone https://github.com/brianm88/brianm88.github.io</code></pre>\n<p>I used this eleventy template: <a href=\"https://github.com/11ty/eleventy-base-blog\">eleventy-base-blog</a></p>\n<p>Cloned those files to my github folder and ran eleventy:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">npx @11ty/eleventy <span class=\"token parameter variable\">--serve</span></code></pre>\n<p>There I had a working skeleton!  But, I wanted a search bar.  So I found a solution with pagefind: <a href=\"https://pagefind.app/\">pagefind</a></p>\n<p>Pretty much just need to insert this line into one of the pages to get it working.  In my case, inserted it in to /my-repo/_includes/layouts/home.njk</p>\n<pre class=\"language-http\" tabindex=\"0\"><code class=\"language-http\">&lt;link href=\"/pagefind/pagefind-ui.css\" rel=\"stylesheet\">\n&lt;script src=\"/pagefind/pagefind-ui.js\">&lt;/script>\n&lt;div id=\"search\">&lt;/div>\n&lt;script>\n    window.addEventListener('DOMContentLoaded', (event) => {\n        new PagefindUI({ element: \"#search\", showSubResults: true });\n    });\n&lt;/script></code></pre>\n<p>Then, you need to run the indexer to let it build an index of your site files.</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">npx <span class=\"token parameter variable\">-y</span> pagefind <span class=\"token parameter variable\">--site</span> _site</code></pre>\n<p>Then I had some weird issues getting github pages to let me select the right folder.  So, I created a /docs/ folder like they suggest, and I just rsynced the stuff into it.  I wrote this into a script so I can execute all this in one command.  The script also takes a commit comment and pushes to github:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token shebang important\">#!/bin/bash</span>\n\n<span class=\"token builtin class-name\">set</span> <span class=\"token parameter variable\">-e</span>\n\n<span class=\"token comment\"># 11ty build</span>\nnpx @11ty/eleventy\n\n<span class=\"token comment\"># pagefind build index</span>\nnpx <span class=\"token parameter variable\">-y</span> pagefind <span class=\"token parameter variable\">--site</span> _site/\n\n<span class=\"token comment\"># rsync to gitpages folder</span>\n<span class=\"token function\">rsync</span> <span class=\"token parameter variable\">-arui</span> <span class=\"token parameter variable\">--delete</span> _site/ docs\n\n<span class=\"token comment\"># Prompt for commit message</span>\n<span class=\"token builtin class-name\">echo</span> <span class=\"token string\">\"Enter commit message:\"</span>\n<span class=\"token builtin class-name\">read</span> commit_message\n\n<span class=\"token comment\"># git operations</span>\n<span class=\"token function\">git</span> <span class=\"token function\">add</span> docs\n<span class=\"token function\">git</span> commit <span class=\"token parameter variable\">-m</span> <span class=\"token string\">\"<span class=\"token variable\">$commit_message</span>\"</span>\n<span class=\"token function\">git</span> push <span class=\"token parameter variable\">-u</span> origin main</code></pre>\n",
			"date_published": "2024-03-03T00:00:00Z"
		}
		,
		{
			"id": "https://stinky.blog/blog/pmx-power-consumption/",
			"url": "https://stinky.blog/blog/pmx-power-consumption/",
			"title": "Reducing power consumption of Proxmox nodes",
			"content_html": "<p>I noticed the other day that my proxmox nodes are running at max turbo frequency all the time. Even when there is virtually zero activity, the 8700 and 7700k are sitting at 4.2ghz+ on all cores. The little x270 stays locked at 3.4ghz on its two cores. Since these servers idle a huge amount, they really dont need to be at max turbo constantly. I saw it recommended on the Proxmox forum to change the cpu governor. Does it work?</p>\n<h2 id=\"let-s-measure-the-power-consumption\" tabindex=\"-1\">Let's measure the power consumption. <a class=\"header-anchor\" href=\"https://stinky.blog/blog/pmx-power-consumption/\">#</a></h2>\n<p>First, we need to install linux-cpupower</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">apt</span> <span class=\"token function\">install</span> linux-cpupower</code></pre>\n<p>Then we can run turbostat to get a rough idea:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">turbostat quiet show Package,Busy%,Bzy_MHz,PkgTmp,PkgWatt,CoreTmp interval <span class=\"token number\">5</span></code></pre>\n<p>With the default governor, my i7-8700 was idling at around ~8.2 watts according to &quot;PkgWatt&quot;.</p>\n<h2 id=\"let-s-change-the-cpu-governor\" tabindex=\"-1\">Let's change the cpu governor <a class=\"header-anchor\" href=\"https://stinky.blog/blog/pmx-power-consumption/\">#</a></h2>\n<p>Changing the governor is pretty easy:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token builtin class-name\">echo</span> powersave <span class=\"token operator\">|</span> <span class=\"token function\">tee</span> /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor</code></pre>\n<p>Now run the turbostat command again to see how the cpu frequency and power consumption have changed.</p>\n<p>My i7-8700 is now idling around ~2.9 watts according to &quot;PkgWatt&quot;.</p>\n<p>Pretty nice reductions! Havent noticed any changes in performance for my normal services, since the turbo just ramps back up as expected when you apply a load.</p>\n<p>You can revert the change back to default easily:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token builtin class-name\">echo</span> performance <span class=\"token operator\">|</span> <span class=\"token function\">tee</span> /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor</code></pre>\n<h2 id=\"to-make-this-setting-persist-on-reboot\" tabindex=\"-1\">To make this setting persist on reboot: <a class=\"header-anchor\" href=\"https://stinky.blog/blog/pmx-power-consumption/\">#</a></h2>\n<p>You need to add a line to your crontab.  Open up the root user's crontab:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">crontab</span> <span class=\"token parameter variable\">-e</span></code></pre>\n<p>and add the following line at the bottom:</p>\n<p>@reboot echo &quot;powersave&quot; | tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor</p>\n<p>Save and reboot to test it.  Happy homelabbing!</p>\n<p>Happy homelabbing!</p>\n",
			"date_published": "2023-09-07T00:00:00Z"
		}
		,
		{
			"id": "https://stinky.blog/blog/pmx-certificate-error/",
			"url": "https://stinky.blog/blog/pmx-certificate-error/",
			"title": "Proxmox TLS, SSH, Certificate Errors",
			"content_html": "<p>Occasionally while adding/removing a node or making other significant changes to your Proxmox cluster, you'll get some errors about unauthorized SSH keys or Certificates.  You might be unable to migrate VMs/containers, unable to use virtual consoles, or unable to access the web interface at all.</p>\n<p>One example error:</p>\n<blockquote>\n<p>tls_process_server_certificate: certificate verify failed (596)</p>\n</blockquote>\n<p>Generally, executing the following command will fix it right up:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">pvecm updatecerts <span class=\"token parameter variable\">-F</span> <span class=\"token operator\">&amp;&amp;</span> systemctl restart pvedaemon pveproxy</code></pre>\n<p>Sometimes, the nuclear option is required.  That means deleting all instances of the problem node from SSH known_hosts, verifying /etc/hosts info is correct on each node, and then executing the following:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">pvecm updatecerts <span class=\"token parameter variable\">-F</span>\n\n<span class=\"token function\">service</span> pve-cluster stop <span class=\"token operator\">&amp;&amp;</span> <span class=\"token function\">service</span> corosync stop <span class=\"token operator\">&amp;&amp;</span> <span class=\"token function\">service</span> pvestatd stop <span class=\"token operator\">&amp;&amp;</span> <span class=\"token function\">service</span> pveproxy stop <span class=\"token operator\">&amp;&amp;</span> <span class=\"token function\">service</span> pvedaemon stop\n\n<span class=\"token function\">service</span> pve-cluster start <span class=\"token operator\">&amp;&amp;</span> <span class=\"token function\">service</span> corosync start <span class=\"token operator\">&amp;&amp;</span> <span class=\"token function\">service</span> pvestatd start <span class=\"token operator\">&amp;&amp;</span> <span class=\"token function\">service</span> pveproxy start</code></pre>\n<p>I have had these errors occur after reinstalling Proxmox on a node and attempting to rejoin the cluster with the same hostname/ip.  Performing the steps above usually gets me back in business pretty quickly.</p>\n",
			"date_published": "2023-01-01T00:00:00Z"
		}
		,
		{
			"id": "https://stinky.blog/blog/easyengine/",
			"url": "https://stinky.blog/blog/easyengine/",
			"title": "easyengine: simple wordpress + ssl deployment",
			"content_html": "<h2 id=\"baby-s-first-vps\" tabindex=\"-1\">Babys first VPS! <a class=\"header-anchor\" href=\"https://stinky.blog/blog/easyengine/\">#</a></h2>\n<p>Now that the homelab cluster is running multiple external services, Im starting to hit some speed bumps. Using my single domain name with tons of port numbers was working okay to keep services separated for personal use. But now with friends and family connecting and using some of these services, its time to switch to easy-to-remember subdomains. I will use a reverse proxy to intercept https requests and send them to the proper IPs and ports.</p>\n<p>That has been easier said than done, though! I have a lot more to learn about virtual hosts, ssl redirect loops, and how to format those dang config files!</p>\n<p>A VPS will allow me to keep some of my crap running externally while I figure all of that out.</p>\n<h2 id=\"let-s-begin-buy-a-vps-and-start-it\" tabindex=\"-1\">Lets begin  Buy a vps and start it <a class=\"header-anchor\" href=\"https://stinky.blog/blog/easyengine/\">#</a></h2>\n<p>I was able to find a 1 core, 1.5gb KVM VPS with 3TB monthly bandwidth and 30gb ssd for $16/year from <a href=\"https://my.racknerd.com/aff.php?aff=6660\">RackNerd!</a> Not a bad deal.\nIn the RackNerd control panel, I chose Ubuntu 22.04 as the OS for this vps.</p>\n<p>Once you start it up, they will email you some credentials to log in via ssh.</p>\n<p>After logging in, lets install the latest security updates:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">apt</span> update <span class=\"token operator\">&amp;&amp;</span> <span class=\"token function\">apt</span> upgrade <span class=\"token parameter variable\">-y</span></code></pre>\n<p>Use wget to download the easyengine installation script:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">wget</span> <span class=\"token parameter variable\">-qO</span> ee https://rt.cx/ee4 <span class=\"token operator\">&amp;&amp;</span> <span class=\"token function\">bash</span> ee</code></pre>\n<p>After the script finishes up, easyengine is ready to go.</p>\n<h2 id=\"create-a-site\" tabindex=\"-1\">Create a site <a class=\"header-anchor\" href=\"https://stinky.blog/blog/easyengine/\">#</a></h2>\n<p>For most users, a single site with proxy caching on and SSL enabled through Lets Encrypt is the best choice:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">ee site create stinky.blog type<span class=\"token operator\">=</span>wp ssl<span class=\"token operator\">=</span>le proxy-cache<span class=\"token operator\">=</span>on proxy-cache-max-size<span class=\"token operator\">=</span>1g proxy-cache-max-time<span class=\"token operator\">=</span>30s</code></pre>\n<p>Replace stinky.blog with your domain.</p>\n<p>Thats it its online! Access your site at http://<em>your_url</em>.com/wp-admin/ and start creating pages.</p>\n",
			"date_published": "2022-12-30T00:00:00Z"
		}
		,
		{
			"id": "https://stinky.blog/blog/pmx-qbit-wg-lxc/",
			"url": "https://stinky.blog/blog/pmx-qbit-wg-lxc/",
			"title": "Proxmox + Qbittorrent + Wireguard + Samba LXC",
			"content_html": "<p>A google search for how to create this type of container will bring up a bunch of malarkey. It doesnt have to be that complicated. You can set this up in a few minutes super easily. The result is an extremely lightweight and effective torrent box that you can control remotely. It works great on very modest hardware even with lots of traffic flowing.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://stinky.blog/img/0p3kt2JHsC-579.avif 579w\"><source type=\"image/webp\" srcset=\"https://stinky.blog/img/0p3kt2JHsC-579.webp 579w\"><img alt=\"container info\" loading=\"lazy\" decoding=\"async\" src=\"https://stinky.blog/img/0p3kt2JHsC-579.jpeg\" width=\"579\" height=\"346\"></picture></p>\n<h2 id=\"first-spin-up-a-container\" tabindex=\"-1\">First, spin up a container. <a class=\"header-anchor\" href=\"https://stinky.blog/blog/pmx-qbit-wg-lxc/\">#</a></h2>\n<p><picture><source type=\"image/avif\" srcset=\"https://stinky.blog/img/RQSkXuO37I-791.avif 791w\"><source type=\"image/webp\" srcset=\"https://stinky.blog/img/RQSkXuO37I-791.webp 791w\"><img alt=\"container creation\" loading=\"lazy\" decoding=\"async\" src=\"https://stinky.blog/img/RQSkXuO37I-791.jpeg\" width=\"791\" height=\"387\"></picture></p>\n<p>Click on the local storage of one of your nodes, go to container templates, and click the Templates button. I am using the ubuntu 22.10-standard template, only 129mb.</p>\n<p>After downloading the template, right click your node and create the container. On the first page, make sure to uncheck unprivileged container so that we will have full write access to the samba share. If you are storing files some other way, you can leave it unprivileged. (You can also achieve write access to cifs shares with an unprivileged container through user mapping if you so choose.)</p>\n<p>Select the ubuntu template on the next page. I went with the defaults for all the other options except 2 cpu cores and a static IP address.</p>\n<h2 id=\"start-the-container\" tabindex=\"-1\">Start the container! <a class=\"header-anchor\" href=\"https://stinky.blog/blog/pmx-qbit-wg-lxc/\">#</a></h2>\n<p>Now we can start the container and do some stuff.</p>\n<p>First, login with username root and the password you set during creation. Update everything with</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">apt</span> update <span class=\"token operator\">&amp;&amp;</span> <span class=\"token function\">apt</span> upgrade <span class=\"token parameter variable\">-y</span></code></pre>\n<p>Then, we need to install a few things</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">apt</span> <span class=\"token function\">install</span> wireguard wireguard-tools <span class=\"token function\">curl</span> qbittorrent-nox cifs-utils iftop</code></pre>\n<p>Since we installed cifs-utils in the last step, lets go ahead and mount the network share. Edit your fstab file:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">nano</span> /etc/fstab</code></pre>\n<p>I have created a user on my NAS named qbit for this service and added it to the samba permissions. It only has access to a folder for downloads. My fstab looks kinda like this:</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://stinky.blog/img/oxosvwo3TL-875.avif 875w\"><source type=\"image/webp\" srcset=\"https://stinky.blog/img/oxosvwo3TL-875.webp 875w\"><img alt=\"fstab config\" loading=\"lazy\" decoding=\"async\" src=\"https://stinky.blog/img/oxosvwo3TL-875.jpeg\" width=\"875\" height=\"79\"></picture></p>\n<p><strong>ctrl + X</strong> to save, then type <strong>reboot</strong>.</p>\n<p>The share should mount on reboot. If not, check for errors with <strong>journalctl -b</strong></p>\n<h2 id=\"let-s-dig-a-wireguard-tunnel\" tabindex=\"-1\">Lets dig a wireguard tunnel <a class=\"header-anchor\" href=\"https://stinky.blog/blog/pmx-qbit-wg-lxc/\">#</a></h2>\n<p>Now you need to log into your VPN provider of choice and download your wireguard configuration. One easy way to do this would be to drop it on your NAS if you have connected one in the last step.</p>\n<p>Navigate to wherever you put that config file so we can move it to its final resting place. Below, mine is named wireguard-vpn.conf:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">mv</span> wireguard-vpn.conf /etc/wireguard/wireguard-vpn.conf <span class=\"token operator\">&amp;&amp;</span> <span class=\"token builtin class-name\">cd</span> /etc/wireguard <span class=\"token operator\">&amp;&amp;</span> <span class=\"token function\">ls</span></code></pre>\n<p>Lets see if that bad boy works:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">wg-quick up wireguard-vpn</code></pre>\n<p><picture><source type=\"image/avif\" srcset=\"https://stinky.blog/img/qBkKeZntks-836.avif 836w\"><source type=\"image/webp\" srcset=\"https://stinky.blog/img/qBkKeZntks-836.webp 836w\"><img alt=\"wireguard output\" loading=\"lazy\" decoding=\"async\" src=\"https://stinky.blog/img/qBkKeZntks-836.jpeg\" width=\"836\" height=\"333\"></picture></p>\n<p>If you connected successfully, typing <strong>ip addr show</strong> will list a new tunnel interface at the bottom with your VPN IP!</p>\n<p>Now make it reconnect automatically on reboot:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">systemctl <span class=\"token builtin class-name\">enable</span> wg-quick@wireguard-vpn</code></pre>\n<p>Reboot and hit it with another <strong>ip addr show</strong> to make sure were still connected to the tunnel!</p>\n<h2 id=\"enable-qbittorrent-nox\" tabindex=\"-1\">Enable qbittorrent-nox <a class=\"header-anchor\" href=\"https://stinky.blog/blog/pmx-qbit-wg-lxc/\">#</a></h2>\n<p>Were on the home stretch! Now make a service that will start qbittorrent-nox automatically on boot:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">nano</span> /etc/systemd/system/qbittorrent-nox.service</code></pre>\n<p>Well keep it super simple:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token punctuation\">[</span>Unit<span class=\"token punctuation\">]</span>\n<span class=\"token assign-left variable\">Description</span><span class=\"token operator\">=</span>qBittorrent-nox <span class=\"token function\">service</span>\n<span class=\"token assign-left variable\">Documentation</span><span class=\"token operator\">=</span>man:qbittorrent-nox<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n<span class=\"token assign-left variable\">Wants</span><span class=\"token operator\">=</span>network-online.target\n<span class=\"token assign-left variable\">After</span><span class=\"token operator\">=</span>network-online.target nss-lookup.target\n\n<span class=\"token punctuation\">[</span>Service<span class=\"token punctuation\">]</span>\n<span class=\"token assign-left variable\">Type</span><span class=\"token operator\">=</span>exec\n<span class=\"token assign-left variable\">ExecStart</span><span class=\"token operator\">=</span>/usr/bin/qbittorrent-nox\n\n<span class=\"token punctuation\">[</span>Install<span class=\"token punctuation\">]</span>\n<span class=\"token assign-left variable\">WantedBy</span><span class=\"token operator\">=</span>multi-user.target</code></pre>\n<p>Now enable it and reboot to see if it works:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">systemctl <span class=\"token builtin class-name\">enable</span> qbittorrent-nox <span class=\"token operator\">&amp;&amp;</span> systemctl daemon-reload <span class=\"token operator\">&amp;&amp;</span> <span class=\"token function\">reboot</span></code></pre>\n<p>Did it work?? You can try it by opening your web browser and typing in the local IP of the machine followed by port 8080!</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://stinky.blog/img/WX1esYhBMp-759.avif 759w\"><source type=\"image/webp\" srcset=\"https://stinky.blog/img/WX1esYhBMp-759.webp 759w\"><img alt=\"working qbit interface\" loading=\"lazy\" decoding=\"async\" src=\"https://stinky.blog/img/WX1esYhBMp-759.jpeg\" width=\"759\" height=\"577\"></picture></p>\n<h2 id=\"bind-qbt-nox-to-wireguard-interface\" tabindex=\"-1\">Bind Qbt-nox to wireguard interface <a class=\"header-anchor\" href=\"https://stinky.blog/blog/pmx-qbit-wg-lxc/\">#</a></h2>\n<p>Last step! Go to <strong>Tools -&gt; Options -&gt; Advanced</strong> and set the client to ONLY use the wireguard tunnel that we have created. If your VPN provides you a static IP, you can optionally set the client to ONLY use this IP as well.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://stinky.blog/img/Ytfrprzav2-837.avif 837w\"><source type=\"image/webp\" srcset=\"https://stinky.blog/img/Ytfrprzav2-837.webp 837w\"><img alt=\"bind to wireguard\" loading=\"lazy\" decoding=\"async\" src=\"https://stinky.blog/img/Ytfrprzav2-837.jpeg\" width=\"837\" height=\"969\"></picture></p>\n<p>Now set your download folder to your samba share in the Downloads tab.</p>\n<p>Thats it! Now you can log in through this web interface from now on. You never have to access the container directly again. Add torrents by copying and pasting the magnet links into the webui from your phone or any other device!</p>\n<p>Ensure that traffic is flowing through the wireguard tunnel as expected by running the <strong>iftop</strong> utility we downloaded earlier.</p>\n",
			"date_published": "2022-12-01T00:00:00Z"
		}
		,
		{
			"id": "https://stinky.blog/blog/e-waste/e-waste-resurrection/",
			"url": "https://stinky.blog/blog/e-waste/e-waste-resurrection/",
			"title": "e-waste resurrection",
			"content_html": "<p>Building a homelab on the cheap means using what you have laying aroundeven if what you have laying around is a dead Dell Inspiron 3521 from a decade ago. This laptop has already lived several lives. It got the wife through college. Before that, it traveled with the mother-in-law for business. It was pretty bad even back then, with a bendy plastic shell, mushy keyboard, and a screen like a gas pump. It does have an ivybridge i3, though! A 17-watt, 2 core, 4 thread behemoth locked at 1.9ghz with no turbo option. It has vt-d support and some usb ports, so it will be perfect as a node in my cluster for light containers and VMs like my NAS and Wireguard tunnels.</p>\n<p>The only problem: it doesnt boot. It doesnt even beep!</p>\n<p>Of course the cmos battery had died after all these years. Changing the battery got it to post! but only once. I accidentally knocked the cmos battery back out while it was running and corrupted the bios. It was SUPER dead this time, the cpu fan would only spin a partial turn before giving up.</p>\n<p>But never fear! Fixing a corrupted bios is pretty simple. The only two tools required are another working computer and a ch341a programmer (about $10 on Amazon) like this:</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://stinky.blog/img/sXSKRFU8_o-400.avif 400w\"><source type=\"image/webp\" srcset=\"https://stinky.blog/img/sXSKRFU8_o-400.webp 400w\"><img alt=\"CH341a programmer\" loading=\"lazy\" decoding=\"async\" src=\"https://stinky.blog/img/sXSKRFU8_o-400.jpeg\" width=\"400\" height=\"396\"></picture></p>\n<p>I found a dump of the original bios in a 2014 forum post on badcaps.net (thanks siddiq from ghana!).</p>\n<p>The ch341a comes with an 8-pin clip that connects directly to the pins on the bios chip. It is a little bit wobbly, and it will not read properly until it is making good contact with all 8 pins. You can make sure its working correctly by dumping the bios to a file, and then verifying the checksum against the file. The flashrom guide here was super easy to follow.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://stinky.blog/img/3jRVsZxj9J-400.avif 400w\"><source type=\"image/webp\" srcset=\"https://stinky.blog/img/3jRVsZxj9J-400.webp 400w\"><img alt=\"CH341a hooked up to bios chip and thinkpad\" loading=\"lazy\" decoding=\"async\" src=\"https://stinky.blog/img/3jRVsZxj9J-400.jpeg\" width=\"400\" height=\"300\"></picture></p>\n<p>Flashrom autodetected the Winbond bios chip, I made a backup dump, and the checksum matched on the first try. I went ahead with flashrom -w on the dump I found online and tadaaaa!</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://stinky.blog/img/feu1EXEmv2-400.avif 400w\"><source type=\"image/webp\" srcset=\"https://stinky.blog/img/feu1EXEmv2-400.webp 400w\"><img alt=\"e-waste resurrected!  ready to begin a proxmox cluster.\" loading=\"lazy\" decoding=\"async\" src=\"https://stinky.blog/img/feu1EXEmv2-400.jpeg\" width=\"400\" height=\"300\"></picture></p>\n<p>It works! Now it is a fully functioning node in my Proxmox cluster. On to rescuing more e-waste for the homelab.</p>\n",
			"date_published": "2022-12-01T00:00:00Z"
		}
		
	]
}
